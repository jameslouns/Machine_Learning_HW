{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lounsbury-A4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQG4aW56ILlp"
      },
      "source": [
        "# A4 Classification of Hand-Drawn Digits\n",
        "\n",
        "In this assignment, you will define a new class named `NeuralNetworkClassifier` that extends the `NeuralNetwork` class provided here and is the solution to Assignment A2.  You will use `NeuralNetworkClassifier` to train a classifier of hand-drawn digits.\n",
        "\n",
        "You will also define the function `confusion_matrix`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL3C6tVsILlq"
      },
      "source": [
        "## `NeuralNetwork` class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrQik0CdILlr"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lvdBle9ILlx"
      },
      "source": [
        "The following code cell will write its contents to `optimizers.py` so the `import optimizers` statement in the code cell after it will work correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1paHjL6hILlx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b398f05-3a07-46e4-a572-b0c41b4b2b41"
      },
      "source": [
        "%%writefile optimizers.py\n",
        "import numpy as np\n",
        "\n",
        "######################################################################\n",
        "## class Optimizers()\n",
        "######################################################################\n",
        "\n",
        "class Optimizers():\n",
        "\n",
        "    def __init__(self, all_weights):\n",
        "        '''all_weights is a vector of all of a neural networks weights concatenated into a one-dimensional vector'''\n",
        "        \n",
        "        self.all_weights = all_weights\n",
        "\n",
        "        # The following initializations are only used by adam.\n",
        "        # Only initializing m, v, beta1t and beta2t here allows multiple calls to adam to handle training\n",
        "        # with multiple subsets (batches) of training data.\n",
        "        self.mt = np.zeros_like(all_weights)\n",
        "        self.vt = np.zeros_like(all_weights)\n",
        "        self.beta1 = 0.9\n",
        "        self.beta2 = 0.999\n",
        "        self.beta1t = 1\n",
        "        self.beta2t = 1\n",
        "\n",
        "        \n",
        "    def sgd(self, error_f, gradient_f, fargs=[], n_epochs=100, learning_rate=0.001, verbose=True, error_convert_f=None):\n",
        "        '''\n",
        "error_f: function that requires X and T as arguments (given in fargs) and returns mean squared error.\n",
        "gradient_f: function that requires X and T as arguments (in fargs) and returns gradient of mean squared error\n",
        "            with respect to each weight.\n",
        "error_convert_f: function that converts the standardized error from error_f to original T units.\n",
        "        '''\n",
        "\n",
        "        error_trace = []\n",
        "        epochs_per_print = n_epochs // 10\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "\n",
        "            error = error_f(*fargs)\n",
        "            grad = gradient_f(*fargs)\n",
        "\n",
        "            # Update all weights using -= to modify their values in-place.\n",
        "            self.all_weights -= learning_rate * grad\n",
        "\n",
        "            if error_convert_f:\n",
        "                error = error_convert_f(error)\n",
        "            error_trace.append(error)\n",
        "\n",
        "            if verbose and ((epoch + 1) % max(1, epochs_per_print) == 0):\n",
        "                print(f'sgd: Epoch {epoch+1:d} Error={error:.5f}')\n",
        "\n",
        "        return error_trace\n",
        "\n",
        "    def adam(self, error_f, gradient_f, fargs=[], n_epochs=100, learning_rate=0.001, verbose=True, error_convert_f=None):\n",
        "        '''\n",
        "error_f: function that requires X and T as arguments (given in fargs) and returns mean squared error.\n",
        "gradient_f: function that requires X and T as arguments (in fargs) and returns gradient of mean squared error\n",
        "            with respect to each weight.\n",
        "error_convert_f: function that converts the standardized error from error_f to original T units.\n",
        "        '''\n",
        "\n",
        "        alpha = learning_rate  # learning rate called alpha in original paper on adam\n",
        "        epsilon = 1e-8\n",
        "        error_trace = []\n",
        "        epochs_per_print = n_epochs // 10\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "\n",
        "            error = error_f(*fargs)\n",
        "            grad = gradient_f(*fargs)\n",
        "\n",
        "            self.mt[:] = self.beta1 * self.mt + (1 - self.beta1) * grad\n",
        "            self.vt[:] = self.beta2 * self.vt + (1 - self.beta2) * grad * grad\n",
        "            self.beta1t *= self.beta1\n",
        "            self.beta2t *= self.beta2\n",
        "\n",
        "            m_hat = self.mt / (1 - self.beta1t)\n",
        "            v_hat = self.vt / (1 - self.beta2t)\n",
        "\n",
        "            # Update all weights using -= to modify their values in-place.\n",
        "            self.all_weights -= alpha * m_hat / (np.sqrt(v_hat) + epsilon)\n",
        "    \n",
        "            if error_convert_f:\n",
        "                error = error_convert_f(error)\n",
        "            error_trace.append(error)\n",
        "\n",
        "            if verbose and ((epoch + 1) % max(1, epochs_per_print) == 0):\n",
        "                print(f'Adam: Epoch {epoch+1:d} Error={error:.5f}')\n",
        "\n",
        "        return error_trace\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.ion()\n",
        "\n",
        "    def parabola(wmin):\n",
        "        return ((w - wmin) ** 2)[0]\n",
        "\n",
        "    def parabola_gradient(wmin):\n",
        "        return 2 * (w - wmin)\n",
        "\n",
        "    w = np.array([0.0])\n",
        "    optimizer = Optimizers(w)\n",
        "\n",
        "    wmin = 5\n",
        "    optimizer.sgd(parabola, parabola_gradient, [wmin],\n",
        "                  n_epochs=500, learning_rate=0.1)\n",
        "\n",
        "    print(f'sgd: Minimum of parabola is at {wmin}. Value found is {w}')\n",
        "\n",
        "    w = np.array([0.0])\n",
        "    optimizer = Optimizers(w)\n",
        "    optimizer.adam(parabola, parabola_gradient, [wmin],\n",
        "                   n_epochs=500, learning_rate=0.1)\n",
        "    \n",
        "    print(f'adam: Minimum of parabola is at {wmin}. Value found is {w}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing optimizers.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrln6bUhILl2"
      },
      "source": [
        "import numpy as np\n",
        "import optimizers\n",
        "import sys  # for sys.float_info.epsilon\n",
        "\n",
        "######################################################################\n",
        "## class NeuralNetwork()\n",
        "######################################################################\n",
        "\n",
        "class NeuralNetwork():\n",
        "\n",
        "\n",
        "    def __init__(self, n_inputs, n_hiddens_per_layer, n_outputs, activation_function='tanh'):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_outputs = n_outputs\n",
        "        self.activation_function = activation_function\n",
        "\n",
        "        # Set self.n_hiddens_per_layer to [] if argument is 0, [], or [0]\n",
        "        if n_hiddens_per_layer == 0 or n_hiddens_per_layer == [] or n_hiddens_per_layer == [0]:\n",
        "            self.n_hiddens_per_layer = []\n",
        "        else:\n",
        "            self.n_hiddens_per_layer = n_hiddens_per_layer\n",
        "\n",
        "        # Initialize weights, by first building list of all weight matrix shapes.\n",
        "        n_in = n_inputs\n",
        "        shapes = []\n",
        "        for nh in self.n_hiddens_per_layer:\n",
        "            shapes.append((n_in + 1, nh))\n",
        "            n_in = nh\n",
        "        shapes.append((n_in + 1, n_outputs))\n",
        "\n",
        "        # self.all_weights:  vector of all weights\n",
        "        # self.Ws: list of weight matrices by layer\n",
        "        self.all_weights, self.Ws = self.make_weights_and_views(shapes)\n",
        "\n",
        "        # Define arrays to hold gradient values.\n",
        "        # One array for each W array with same shape.\n",
        "        self.all_gradients, self.dE_dWs = self.make_weights_and_views(shapes)\n",
        "\n",
        "        self.trained = False\n",
        "        self.total_epochs = 0\n",
        "        self.error_trace = []\n",
        "        self.Xmeans = None\n",
        "        self.Xstds = None\n",
        "        self.Tmeans = None\n",
        "        self.Tstds = None\n",
        "\n",
        "\n",
        "    def make_weights_and_views(self, shapes):\n",
        "        # vector of all weights built by horizontally stacking flatenned matrices\n",
        "        # for each layer initialized with uniformly-distributed values.\n",
        "        all_weights = np.hstack([np.random.uniform(size=shape).flat / np.sqrt(shape[0])\n",
        "                                 for shape in shapes])\n",
        "        # Build list of views by reshaping corresponding elements from vector of all weights\n",
        "        # into correct shape for each layer.\n",
        "        views = []\n",
        "        start = 0\n",
        "        for shape in shapes:\n",
        "            size =shape[0] * shape[1]\n",
        "            views.append(all_weights[start:start + size].reshape(shape))\n",
        "            start += size\n",
        "        return all_weights, views\n",
        "\n",
        "\n",
        "    # Return string that shows how the constructor was called\n",
        "    def __repr__(self):\n",
        "        return f'{type(self).__name__}({self.n_inputs}, {self.n_hiddens_per_layer}, {self.n_outputs}, \\'{self.activation_function}\\')'\n",
        "\n",
        "\n",
        "    # Return string that is more informative to the user about the state of this neural network.\n",
        "    def __str__(self):\n",
        "        result = self.__repr__()\n",
        "        if len(self.error_trace) > 0:\n",
        "            return self.__repr__() + f' trained for {len(self.error_trace)} epochs, final training error {self.error_trace[-1]:.4f}'\n",
        "\n",
        "\n",
        "    def train(self, X, T, n_epochs, learning_rate, method='sgd', verbose=True):\n",
        "        '''\n",
        "train: \n",
        "  X: n_samples x n_inputs matrix of input samples, one per row\n",
        "  T: n_samples x n_outputs matrix of target output values, one sample per row\n",
        "  n_epochs: number of passes to take through all samples updating weights each pass\n",
        "  learning_rate: factor controlling the step size of each update\n",
        "  method: is either 'sgd' or 'adam'\n",
        "        '''\n",
        "\n",
        "        # Setup standardization parameters\n",
        "        if self.Xmeans is None:\n",
        "            self.Xmeans = X.mean(axis=0)\n",
        "            self.Xstds = X.std(axis=0)\n",
        "            self.Xstds[self.Xstds == 0] = 1  # So we don't divide by zero when standardizing\n",
        "            self.Tmeans = T.mean(axis=0)\n",
        "            self.Tstds = T.std(axis=0)\n",
        "            \n",
        "        # Standardize X and T\n",
        "        X = (X - self.Xmeans) / self.Xstds\n",
        "        T = (T - self.Tmeans) / self.Tstds\n",
        "\n",
        "        # Instantiate Optimizers object by giving it vector of all weights\n",
        "        optimizer = optimizers.Optimizers(self.all_weights)\n",
        "\n",
        "        # Define function to convert value from error_f into error in original T units, \n",
        "        # but only if the network has a single output. Multiplying by self.Tstds for \n",
        "        # multiple outputs does not correctly unstandardize the error.\n",
        "        if len(self.Tstds) == 1:\n",
        "            error_convert_f = lambda err: (np.sqrt(err) * self.Tstds)[0] # to scalar\n",
        "        else:\n",
        "            error_convert_f = lambda err: np.sqrt(err)[0] # to scalar\n",
        "            \n",
        "\n",
        "        if method == 'sgd':\n",
        "\n",
        "            error_trace = optimizer.sgd(self.error_f, self.gradient_f,\n",
        "                                        fargs=[X, T], n_epochs=n_epochs,\n",
        "                                        learning_rate=learning_rate,\n",
        "                                        verbose=True,\n",
        "                                        error_convert_f=error_convert_f)\n",
        "\n",
        "        elif method == 'adam':\n",
        "\n",
        "            error_trace = optimizer.adam(self.error_f, self.gradient_f,\n",
        "                                         fargs=[X, T], n_epochs=n_epochs,\n",
        "                                         learning_rate=learning_rate,\n",
        "                                         verbose=True,\n",
        "                                         error_convert_f=error_convert_f)\n",
        "\n",
        "        else:\n",
        "            raise Exception(\"method must be 'sgd' or 'adam'\")\n",
        "        \n",
        "        self.error_trace = error_trace\n",
        "\n",
        "        # Return neural network object to allow applying other methods after training.\n",
        "        #  Example:    Y = nnet.train(X, T, 100, 0.01).use(X)\n",
        "        return self\n",
        "\n",
        "    def relu(self, s):\n",
        "        s[s < 0] = 0\n",
        "        return s\n",
        "\n",
        "    def grad_relu(self, s):\n",
        "        return (s > 0).astype(int)\n",
        "    \n",
        "    def forward_pass(self, X):\n",
        "        '''X assumed already standardized. Output returned as standardized.'''\n",
        "        self.Ys = [X]\n",
        "        for W in self.Ws[:-1]:\n",
        "            if self.activation_function == 'relu':\n",
        "                self.Ys.append(self.relu(self.Ys[-1] @ W[1:, :] + W[0:1, :]))\n",
        "            else:\n",
        "                self.Ys.append(np.tanh(self.Ys[-1] @ W[1:, :] + W[0:1, :]))\n",
        "        last_W = self.Ws[-1]\n",
        "        self.Ys.append(self.Ys[-1] @ last_W[1:, :] + last_W[0:1, :])\n",
        "        return self.Ys\n",
        "\n",
        "    # Function to be minimized by optimizer method, mean squared error\n",
        "    def error_f(self, X, T):\n",
        "        Ys = self.forward_pass(X)\n",
        "        mean_sq_error = np.mean((T - Ys[-1]) ** 2)\n",
        "        return mean_sq_error\n",
        "\n",
        "    # Gradient of function to be minimized for use by optimizer method\n",
        "    def gradient_f(self, X, T):\n",
        "        '''Assumes forward_pass just called with layer outputs in self.Ys.'''\n",
        "        error = T - self.Ys[-1]\n",
        "        n_samples = X.shape[0]\n",
        "        n_outputs = T.shape[1]\n",
        "        delta = - error / (n_samples * n_outputs)\n",
        "        n_layers = len(self.n_hiddens_per_layer) + 1\n",
        "        # Step backwards through the layers to back-propagate the error (delta)\n",
        "        for layeri in range(n_layers - 1, -1, -1):\n",
        "            # gradient of all but bias weights\n",
        "            self.dE_dWs[layeri][1:, :] = self.Ys[layeri].T @ delta\n",
        "            # gradient of just the bias weights\n",
        "            self.dE_dWs[layeri][0:1, :] = np.sum(delta, 0)\n",
        "            # Back-propagate this layer's delta to previous layer\n",
        "            if self.activation_function == 'relu':\n",
        "                delta = delta @ self.Ws[layeri][1:, :].T * self.grad_relu(self.Ys[layeri])\n",
        "            else:\n",
        "                delta = delta @ self.Ws[layeri][1:, :].T * (1 - self.Ys[layeri] ** 2)\n",
        "        return self.all_gradients\n",
        "\n",
        "    def use(self, X):\n",
        "        '''X assumed to not be standardized'''\n",
        "        # Standardize X\n",
        "        X = (X - self.Xmeans) / self.Xstds\n",
        "        Ys = self.forward_pass(X)\n",
        "        Y = Ys[-1]\n",
        "        # Unstandardize output Y before returning it\n",
        "        return Y * self.Tstds + self.Tmeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWTG8h5GILl5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "037a0769-92c0-4818-ae9a-6ab910ee876a"
      },
      "source": [
        "X = np.arange(100).reshape((-1, 1))\n",
        "T = (X - 20) ** 3 / 300000\n",
        "\n",
        "hiddens = [10]\n",
        "nnet = NeuralNetwork(X.shape[1], hiddens, T.shape[1])\n",
        "nnet.train(X, T, 250, 0.01, method='adam')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(nnet.error_trace)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(T, label='T')\n",
        "plt.plot(nnet.use(X), label='Y')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adam: Epoch 25 Error=0.23706\n",
            "Adam: Epoch 50 Error=0.22585\n",
            "Adam: Epoch 75 Error=0.21116\n",
            "Adam: Epoch 100 Error=0.18261\n",
            "Adam: Epoch 125 Error=0.13368\n",
            "Adam: Epoch 150 Error=0.08973\n",
            "Adam: Epoch 175 Error=0.07096\n",
            "Adam: Epoch 200 Error=0.06214\n",
            "Adam: Epoch 225 Error=0.05538\n",
            "Adam: Epoch 250 Error=0.04952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe45b8091d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4rmp0bCILl9"
      },
      "source": [
        "## Your `NeuralNetworkClassifier` class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE3p86BtILl_"
      },
      "source": [
        "Complete the following definition of `NeuralNetworkClassifier` as discussed in class. You will need to override the functions\n",
        "\n",
        "* `train`\n",
        "* `error_f`\n",
        "* `gradient_f`\n",
        "* `use`\n",
        "\n",
        "and define the following new functions\n",
        "\n",
        "* `makeIndicatorVars`\n",
        "* `softmax`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOnpsfUCILl_"
      },
      "source": [
        "class NeuralNetworkClassifier(NeuralNetwork):\n",
        "\n",
        "  def makeIndicatorVars(self, T):\n",
        "      # Make sure T is two-dimensional. Should be nSamples x 1.\n",
        "      if T.ndim == 1:\n",
        "          T = T.reshape((-1, 1))\n",
        "      retT = (T == np.unique(T)).astype(int)\n",
        "      return retT\n",
        "      \n",
        "  def softmax (self, X):\n",
        "      fs = np.exp(X)  # N x K\n",
        "      denom = np.sum(fs, axis=1).reshape((-1, 1))\n",
        "      gs = fs / (denom + sys.float_info.epsilon)\n",
        "      return gs\n",
        "\n",
        "  def train(self, X, T, n_epochs, learning_rate, method='sgd', verbose=True):\n",
        "        '''\n",
        "train: \n",
        "  X: n_samples x n_inputs matrix of input samples, one per row\n",
        "  T: n_samples x n_outputs matrix of target output values, one sample per row\n",
        "  n_epochs: number of passes to take through all samples updating weights each pass\n",
        "  learning_rate: factor controlling the step size of each update\n",
        "  method: is either 'sgd' or 'adam'\n",
        "        '''\n",
        "\n",
        "        # Setup standardization parameters\n",
        "        if self.Xmeans is None:\n",
        "            self.Xmeans = X.mean(axis=0)\n",
        "            self.Xstds = X.std(axis=0)\n",
        "            self.Xstds[self.Xstds == 0] = 1  # So we don't divide by zero when standardizing\n",
        "            self.Tmeans = T.mean(axis=0)\n",
        "            self.Tstds = T.std(axis=0)\n",
        "            \n",
        "        # Standardize X and T\n",
        "        X = (X - self.Xmeans) / self.Xstds\n",
        "        self.TtrainI = self.makeIndicatorVars(T)\n",
        "        self.uniqueT=np.unique(T)\n",
        "        # Instantiate Optimizers object by giving it vector of all weights\n",
        "        optimizer = optimizers.Optimizers(self.all_weights)\n",
        "\n",
        "        # Define function to convert value from error_f into error in original T units, \n",
        "        # but only if the network has a single output. Multiplying by self.Tstds for \n",
        "        # multiple outputs does not correctly unstandardize the error.\n",
        "        error_convert_f = lambda nll: (np.exp(-nll))\n",
        "\n",
        "        if method == 'sgd':\n",
        "\n",
        "            error_trace = optimizer.sgd(self.error_f, self.gradient_f,\n",
        "                                        fargs=[X, self.TtrainI], n_epochs=n_epochs,\n",
        "                                        learning_rate=learning_rate,\n",
        "                                        verbose=True,\n",
        "                                        error_convert_f=error_convert_f)\n",
        "\n",
        "        elif method == 'adam':\n",
        "\n",
        "            error_trace = optimizer.adam(self.error_f, self.gradient_f,\n",
        "                                         fargs=[X, self.TtrainI], n_epochs=n_epochs,\n",
        "                                         learning_rate=learning_rate,\n",
        "                                         verbose=True,\n",
        "                                         error_convert_f=error_convert_f)\n",
        "\n",
        "        else:\n",
        "            raise Exception(\"method must be 'sgd' or 'adam'\")\n",
        "        \n",
        "        self.error_trace = error_trace\n",
        "\n",
        "        # Return neural network object to allow applying other methods after training.\n",
        "        #  Example:    Y = nnet.train(X, T, 100, 0.01).use(X)\n",
        "        return self\n",
        "\n",
        "    # Function to be minimized by optimizer method, mean squared error  \n",
        "  def error_f(self, X, T):\n",
        "      temp = self.forward_pass(X)\n",
        "      Y = self.softmax(temp[-1])\n",
        "      #mean_sq_error = np.mean((T - Ys[-1]) ** 2)\n",
        "      return - np.mean((T * np.log(Y)))\n",
        "\n",
        "\n",
        "  # Gradient of function to be minimized for use by optimizer method \n",
        "  # Look at Lecture 10\n",
        "  def gradient_f(self, X, T):\n",
        "      Y = self.softmax(self.Ys[-1])\n",
        "      delta = (Y - T) / (T.shape[0] * T.shape[1])\n",
        "      n_layers = len(self.n_hiddens_per_layer) + 1\n",
        "      for layeri in range(n_layers - 1, -1, -1):\n",
        "            # gradient of all but bias weights\n",
        "            self.dE_dWs[layeri][1:, :] = self.Ys[layeri].T @ delta\n",
        "            # gradient of just the bias weights\n",
        "            self.dE_dWs[layeri][0:1, :] = np.sum(delta, 0)\n",
        "            # Back-propagate this layer's delta to previous layer\n",
        "            if self.activation_function == 'relu':\n",
        "                delta = delta @ self.Ws[layeri][1:, :].T * self.grad_relu(self.Ys[layeri])\n",
        "            else:\n",
        "                delta = delta @ self.Ws[layeri][1:, :].T * (1 - self.Ys[layeri] ** 2)\n",
        "      return self.all_gradients\n",
        "\n",
        "  def use(self, X):\n",
        "      Xtest = ((X - self.Xmeans)/self.Xstds)\n",
        "      #Xtest1 = np.hstack(( np.ones((Xtest.shape[0],1)), Xtest))\n",
        "      temp = self.forward_pass(Xtest)\n",
        "      logregOutput = self.softmax(temp[-1])\n",
        "      predictedTrain = np.argmax(logregOutput,axis=1)\n",
        "      result = np.array(list(map(lambda x: [self.uniqueT[x].astype(int)] , predictedTrain)))\n",
        "      return result , logregOutput\n",
        "      \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq4PZPm1ILmE"
      },
      "source": [
        "Here is a simple test of your new class.  For inputs from 0 to 100, classify values less than or equal to 25 as Class Label 25, greater than 25 and less than or equal to 75 as Class Label 75, and greater than 75 as Class Label 100. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBlHfjdYILmF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "8f8215a1-7d18-4499-9011-9612cefd3b34"
      },
      "source": [
        "X = np.arange(100).reshape((-1, 1))\n",
        "T = X.copy()\n",
        "T[T <= 25] = 25\n",
        "T[np.logical_and(25 < T, T <= 75)] = 75\n",
        "T[T > 75] = 100\n",
        "\n",
        "plt.plot(X, T, 'o-')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Class');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d0783tZILmI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "5362a5e1-6271-41f3-f0ae-b774a8beacb7"
      },
      "source": [
        "hiddens = [10]\n",
        "nnet = NeuralNetworkClassifier(X.shape[1], hiddens, len(np.unique(T)))\n",
        "\n",
        "nnet.train(X, T, 200, 0.01, method='adam', verbose=True)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(nnet.error_trace)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Likelihood')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(T + 5, 'o-', label='T + 5')  # to see, when predicted overlap T very closely\n",
        "plt.plot(nnet.use(X)[0], 'o-', label='Y')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adam: Epoch 20 Error=0.79055\n",
            "Adam: Epoch 40 Error=0.86051\n",
            "Adam: Epoch 60 Error=0.90738\n",
            "Adam: Epoch 80 Error=0.93517\n",
            "Adam: Epoch 100 Error=0.95024\n",
            "Adam: Epoch 120 Error=0.95899\n",
            "Adam: Epoch 140 Error=0.96468\n",
            "Adam: Epoch 160 Error=0.96873\n",
            "Adam: Epoch 180 Error=0.97180\n",
            "Adam: Epoch 200 Error=0.97422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe45b2387b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgaYub-oILmN"
      },
      "source": [
        "## Now for the Hand-Draw Digits\n",
        "\n",
        "We will use a bunch (50,000) images of hand drawn digits from [this deeplearning.net site](http://deeplearning.net/tutorial/gettingstarted.html).  Download `mnist.pkl.gz`. \n",
        "\n",
        "This pickle file includes data already partitioned into training, validation, and test sets.  To read it into python, use the following steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JtW2iMQaeZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24210b83-e3de-4f0a-eb22-70303f0f3733"
      },
      "source": [
        "!curl -O http://deeplearning.net/data/mnist/mnist.pkl.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:31 --:--:--     0curl: (7) Failed to connect to deeplearning.net port 80: Connection timed out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qANvFvDuILmO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "4a882cc9-d11a-42d4-f1cd-e309795562e9"
      },
      "source": [
        "import pickle\n",
        "import gzip\n",
        "\n",
        "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
        "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
        "\n",
        "Xtrain = train_set[0]\n",
        "Ttrain = train_set[1].reshape(-1, 1)\n",
        "\n",
        "Xval = valid_set[0]\n",
        "Tval = valid_set[1].reshape(-1, 1)\n",
        "\n",
        "Xtest = test_set[0]\n",
        "Ttest = test_set[1].reshape(-1, 1)\n",
        "\n",
        "print(Xtrain.shape, Ttrain.shape,  Xval.shape, Tval.shape,  Xtest.shape, Ttest.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a106246ce417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist.pkl.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"write\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mnist.pkl.gz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6wCw3zyILmS"
      },
      "source": [
        "Ttrain[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry-Y9lCpILmV"
      },
      "source": [
        "Those must be the digits.  What the heck is in those 784 columns in the input matrices?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3DuFVxHILmW"
      },
      "source": [
        "plt.plot(Xtrain[0, :]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLKYWnwvILma"
      },
      "source": [
        "Well, values between 0 and 1.  That doesn't help much.  These are actually intensity values for 784 pixels in an image.\n",
        "\n",
        "How can we rearrange these values into an image to be displayed?  We must first figure out how many columns and rows the image would have.  Perhaps the image is a square image, with equal numbers of rows and columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD0wErb4ILmb"
      },
      "source": [
        "import math\n",
        "math.sqrt(784)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVvg2mh6ILme"
      },
      "source": [
        "Ah, cool."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yPCPd9PILmf"
      },
      "source": [
        "28 * 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT9DICPSILmj"
      },
      "source": [
        "Ok Let's reshape it and look at the numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJdhmF39ILmk"
      },
      "source": [
        "image0 = Xtrain[0, :]\n",
        "image0 = image0.reshape(28, 28)\n",
        "image0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfX1jH2FILmq"
      },
      "source": [
        "Not that helpful.  Ok, let's use `matplotlib` to make an image display."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv0Sd59wILmq"
      },
      "source": [
        "plt.imshow(image0);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQMWLL4qILmt"
      },
      "source": [
        "Humm.  Try a grayscale color map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS2yWe8JILmu"
      },
      "source": [
        "plt.imshow(image0, cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw9heSACILmx"
      },
      "source": [
        "With a little more work, we can make it look like a pencil drawing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVte9hQxILm6"
      },
      "source": [
        "plt.imshow(-image0, cmap='gray')  # notice the negative sign\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoW5tremILm-"
      },
      "source": [
        "Looks like a 5.  What class label is associated with this image?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17YMAXbyILm_"
      },
      "source": [
        "Ttrain[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxd5p0ECILnD"
      },
      "source": [
        "Okay.  Makes sense.  Let's look at the first 100 images and their labels, as plot titles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIUgz6K-ILnE"
      },
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(100):\n",
        "    plt.subplot(10, 10, i + 1)\n",
        "    plt.imshow(-Xtrain[i, :].reshape(28, 28), cmap='gray')\n",
        "    plt.title(Ttrain[i, 0])\n",
        "    plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_99NoHFcILnH"
      },
      "source": [
        "Okay.  We are ready to try to classify, right?\n",
        "\n",
        "First we should check the proportions of each digit in the given data partitions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofQLhWTWILnH"
      },
      "source": [
        "classes = np.arange(10)\n",
        "(Ttrain == classes).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn-hDTJ3ILnK"
      },
      "source": [
        "(Ttrain == classes).sum(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u70qYJhILnQ"
      },
      "source": [
        "(Ttrain == classes).sum(axis=0) / Ttrain.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrQ5uzDXILnV"
      },
      "source": [
        "['Ttrain', *(Ttrain == classes).sum(axis=0) / Ttrain.shape[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k12oWsBvILnZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "a3e83a88-e65b-463c-a170-d4634bccd25f"
      },
      "source": [
        "import pandas\n",
        "\n",
        "result = []\n",
        "result.append(['Train', *(Ttrain == classes).sum(axis=0) / Ttrain.shape[0]])\n",
        "result.append(['Tval', *(Tval == classes).sum(axis=0) / Tval.shape[0]])\n",
        "result.append(['Ttest', *(Ttest == classes).sum(axis=0) / Ttest.shape[0]])\n",
        "pandas.DataFrame(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8ad4a797abbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTtrain\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mTtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tval'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mTval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ttest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTtest\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mTtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Ttrain' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE-iEGtWILnh"
      },
      "source": [
        "All very close to 0.1. Super."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGmAJhilILnh"
      },
      "source": [
        "Time for our first experiment.  Let's train a small neural net with 5 hidden units in one layer for a small number of epochs using Adam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9VfR5oCILni"
      },
      "source": [
        "n_epochs = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "np.random.seed(142)\n",
        "\n",
        "nnet = NeuralNetworkClassifier(Xtrain.shape[1], [5], len(classes))\n",
        "nnet.train(Xtrain, Ttrain, n_epochs, learning_rate, method='adam', verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbsIy_FtILns"
      },
      "source": [
        "print(nnet)  # uses the __str__ method"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL-X7OMjILnv"
      },
      "source": [
        "plt.plot(nnet.error_trace);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxzYJ2DwILnx"
      },
      "source": [
        "Now it is time for you to run some longer experiments.  You must write the code to do the following steps:\n",
        "\n",
        "1. For each of at least five different hidden layer structures\n",
        "\n",
        "    1. Train a network for 500 epochs.\n",
        "    1. Collect percent of samples correctly classified in the given train, validate, and test partitions.\n",
        "\n",
        "2. Create a `pandas.DataFrame` with these results and with column headings `('Hidden Layers', 'Train', 'Validate', 'Test', 'Time')` where `'Time'` is the number of seconds required to train each network.\n",
        "\n",
        "3. Retrain a network using the best hidden layer structure, judged by the percent correct on the validation set.\n",
        "4. Use this network to find several images in the test set for which the network's probability of the correct class is the closest to zero, meaning images for which your network does the worst.  Draw these images and discuss why your network might not be doing well for those images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWAmttUCILny"
      },
      "source": [
        "## `confusion_matrix`\n",
        "\n",
        "Now, write a function named `confusion_matrix` that returns a confusion matrix for any classification problem, returned as a `pandas.DataFrame` as shown in Lecture Notes 12.  It must require two arguments, the predicted classes for each sample and the true classes for each sample.  Here is an example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH9DG6bsg9m3"
      },
      "source": [
        "import pandas\n",
        "def confusion_matrix(Y_classes, T):\n",
        "  class_names=np.unique(T)\n",
        "  table = []\n",
        "  for true_class in range(0,10):\n",
        "    row = []\n",
        "    for predicted_class in range(0,10):\n",
        "        row.append(100 * np.mean(Y_classes[T == true_class] == predicted_class))\n",
        "        # row.append(f'{100 * np.mean(Classes[Ttrain == true_class] == predicted_class):0.1f}')\n",
        "    table.append(row)\n",
        "    \n",
        "  print(f'Test percent correct {np.mean(Y_classes == Ttest) * 100:.2f}') \n",
        "\n",
        "  return pandas.DataFrame(table, index=class_names, columns=class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCBAHn0rILny",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "1615013e-8351-4b7f-a2f0-9b6af170088b"
      },
      "source": [
        "Y_classes, Y_probs = nnet.use(Xtest)\n",
        "confusion_matrix(Y_classes, Ttest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test percent correct 83.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>89.897959</td>\n",
              "      <td>0.204082</td>\n",
              "      <td>1.530612</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.326531</td>\n",
              "      <td>1.020408</td>\n",
              "      <td>3.877551</td>\n",
              "      <td>1.326531</td>\n",
              "      <td>0.204082</td>\n",
              "      <td>0.612245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.176211</td>\n",
              "      <td>94.625551</td>\n",
              "      <td>1.321586</td>\n",
              "      <td>1.233480</td>\n",
              "      <td>0.264317</td>\n",
              "      <td>0.176211</td>\n",
              "      <td>0.352423</td>\n",
              "      <td>0.088106</td>\n",
              "      <td>1.762115</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.162791</td>\n",
              "      <td>1.647287</td>\n",
              "      <td>85.658915</td>\n",
              "      <td>2.228682</td>\n",
              "      <td>1.356589</td>\n",
              "      <td>0.387597</td>\n",
              "      <td>3.294574</td>\n",
              "      <td>0.872093</td>\n",
              "      <td>3.100775</td>\n",
              "      <td>0.290698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.792079</td>\n",
              "      <td>8.514851</td>\n",
              "      <td>77.821782</td>\n",
              "      <td>0.693069</td>\n",
              "      <td>3.663366</td>\n",
              "      <td>2.376238</td>\n",
              "      <td>1.683168</td>\n",
              "      <td>3.465347</td>\n",
              "      <td>0.990099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.814664</td>\n",
              "      <td>1.120163</td>\n",
              "      <td>1.120163</td>\n",
              "      <td>0.407332</td>\n",
              "      <td>82.179226</td>\n",
              "      <td>1.731161</td>\n",
              "      <td>0.610998</td>\n",
              "      <td>1.018330</td>\n",
              "      <td>0.407332</td>\n",
              "      <td>10.590631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.690583</td>\n",
              "      <td>0.336323</td>\n",
              "      <td>1.233184</td>\n",
              "      <td>3.139013</td>\n",
              "      <td>1.793722</td>\n",
              "      <td>74.887892</td>\n",
              "      <td>4.708520</td>\n",
              "      <td>0.896861</td>\n",
              "      <td>6.726457</td>\n",
              "      <td>3.587444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.131524</td>\n",
              "      <td>0.208768</td>\n",
              "      <td>3.027140</td>\n",
              "      <td>0.626305</td>\n",
              "      <td>0.521921</td>\n",
              "      <td>5.323591</td>\n",
              "      <td>84.237996</td>\n",
              "      <td>2.400835</td>\n",
              "      <td>0.313152</td>\n",
              "      <td>0.208768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.167315</td>\n",
              "      <td>3.015564</td>\n",
              "      <td>1.361868</td>\n",
              "      <td>0.875486</td>\n",
              "      <td>2.918288</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.583658</td>\n",
              "      <td>84.241245</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.836576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.129363</td>\n",
              "      <td>1.848049</td>\n",
              "      <td>0.821355</td>\n",
              "      <td>6.262834</td>\n",
              "      <td>0.513347</td>\n",
              "      <td>7.905544</td>\n",
              "      <td>1.129363</td>\n",
              "      <td>1.334702</td>\n",
              "      <td>76.591376</td>\n",
              "      <td>2.464066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.081269</td>\n",
              "      <td>1.288404</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.991080</td>\n",
              "      <td>5.748266</td>\n",
              "      <td>1.189296</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.567889</td>\n",
              "      <td>1.090188</td>\n",
              "      <td>84.043608</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0          1          2  ...          7          8          9\n",
              "0  89.897959   0.204082   1.530612  ...   1.326531   0.204082   0.612245\n",
              "1   0.176211  94.625551   1.321586  ...   0.088106   1.762115   0.000000\n",
              "2   1.162791   1.647287  85.658915  ...   0.872093   3.100775   0.290698\n",
              "3   0.000000   0.792079   8.514851  ...   1.683168   3.465347   0.990099\n",
              "4   0.814664   1.120163   1.120163  ...   1.018330   0.407332  10.590631\n",
              "5   2.690583   0.336323   1.233184  ...   0.896861   6.726457   3.587444\n",
              "6   3.131524   0.208768   3.027140  ...   2.400835   0.313152   0.208768\n",
              "7   1.167315   3.015564   1.361868  ...  84.241245   0.000000   5.836576\n",
              "8   1.129363   1.848049   0.821355  ...   1.334702  76.591376   2.464066\n",
              "9   2.081269   1.288404   0.000000  ...   3.567889   1.090188  84.043608\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "uLsEsJdzHbyV",
        "outputId": "aa73c411-3d46-4d39-cf20-6b17f36829db"
      },
      "source": [
        "import time\r\n",
        "results=[]\r\n",
        "for i in [[5],[3,5],[5,3],[3,5,3],[5,3,5]]:\r\n",
        "  nnet=NeuralNetworkClassifier(Xtrain.shape[1], i, len(classes)))\r\n",
        "  StartTime=time.time()\r\n",
        "  nnet.train(Xtrain, Ttrain, 500, .01, method='adam', verbose=False)\r\n",
        "  StopTime=time.time()\r\n",
        "  Y,prob=nnet.use(Xtrain)\r\n",
        "  train=np.mean(Y == Ttrain) * 100\r\n",
        "  Y,prob=nnet.use(Xtest)\r\n",
        "  test=np.mean(Y == Ttest) * 100\r\n",
        "  Y,prob=nnet.use(Xvalidate)\r\n",
        "  val=np.mean(Y == Tvalidate) * 100\r\n",
        "  results.append([i,train,val,test,StartTime-StopTime])\r\n",
        "df = pandas.DataFrame(results,columns=['Hidden Layers', 'Train', 'Validate', 'Test', 'Time'])\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-57d93428fbac>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    nnet=NeuralNetworkClassifier(Xtrain.shape[1], i, len(classes)))\u001b[0m\n\u001b[0m                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88B3qUWD7prS"
      },
      "source": [
        "curr=0\r\n",
        "HL=[]\r\n",
        "for i in results:\r\n",
        "  if i[2]>curr:\r\n",
        "    curr=i[2]\r\n",
        "    HL=i[0]\r\n",
        "Fnnet=NeuralNetworkClassifier(Xtrain.shape[1], HL, len(classes)))\r\n",
        "Fnnet.nnet.train(Xtrain, Ttrain, 500, .01, method='adam', verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUhyE7wA8pyq"
      },
      "source": [
        "unable to do last part without dataset working"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nzEE427ILn3"
      },
      "source": [
        "## Grading and Check-In\n",
        "\n",
        "Submit assignments through Canvas following the pattern of the previous assignments. 70 points for correct code, 30 points for assignment meetings. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1u9Tm8uILn3"
      },
      "source": [
        "## Extra Credit\n",
        "Earn 5 extra credit point on this assignment by doing the following.\n",
        "\n",
        "1. Combine the train, validate, and test partitions loaded from the MNIST data file into two matrices, `X` and `T`. \n",
        "2. Using `adam` , `relu` and just one value of `learning_rate` and `n_epochs`, compare several hidden layer architectures. Do so by applying our `generate_k_fold_cross_validation_sets` function as defined in Lecture Notes 12 which forms stratified partitioning, for use in classification problems, to your `X` and `T` matrices using `n_fold` of 3.\n",
        "3. Show results and discuss which architectures you find works the best, and how you determined this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DD9gH8iILn4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}